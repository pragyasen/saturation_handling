{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqAIFAiFl8GC",
        "outputId": "66235032-a8cc-421d-d005-793a13de1152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 57 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 5.1 MB/s \n",
            "\u001b[?25hMounted at /content/drive\n",
            "importing Jupyter notebook from /nbs/resnet_layers.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Contains definitions for post- and pre-activation forms of ResNet and ResNet-RS models.\n",
        "Residual networks (ResNets) were proposed in:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n",
        "[3] Irwan Bello, William Fedus, Xianzhi Du, Ekin D. Cubuk, Aravind Srinivas,\n",
        "Tsung-Yi Lin, Jonathon Shlens, Barret Zoph\n",
        "    Revisiting ResNets: Improved Training and Scaling Strategies.\n",
        "    arXiv:2103.07579\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "!pip install kora -q\n",
        "from kora import drive\n",
        "drive.link_nbs()\n",
        "\n",
        "import resnet_layers\n",
        "\n",
        "\n",
        "MOVING_AVERAGE_DECAY = 0.9\n",
        "EPSILON = 1e-5\n",
        "\n",
        "LAYER_BN_RELU = 'bn_relu'\n",
        "LAYER_EVONORM_B0 = 'evonorm_b0'\n",
        "LAYER_EVONORM_S0 = 'evonorm_s0'\n",
        "LAYER_EVONORMS = [\n",
        "    LAYER_EVONORM_B0,\n",
        "    LAYER_EVONORM_S0,\n",
        "]\n",
        "\n",
        "\n",
        "def norm_activation(\n",
        "    inputs, is_training, layer=LAYER_BN_RELU, nonlinearity=True,\n",
        "    init_zero=False, data_format='channels_first',\n",
        "    bn_momentum=MOVING_AVERAGE_DECAY):\n",
        "  \"\"\"Normalization-activation layer.\"\"\"\n",
        "  if layer == LAYER_BN_RELU:\n",
        "    return batch_norm_relu(\n",
        "        inputs, is_training, relu=nonlinearity,\n",
        "        init_zero=init_zero, data_format=data_format,\n",
        "        bn_momentum=bn_momentum)\n",
        "  elif layer in LAYER_EVONORMS:\n",
        "    return evonorm(\n",
        "        inputs, is_training, layer=layer, nonlinearity=nonlinearity,\n",
        "        init_zero=init_zero, data_format=data_format)\n",
        "  else:\n",
        "    raise ValueError('Unknown normalization-activation layer: {}'.format(layer))\n",
        "\n",
        "\n",
        "def batch_norm_relu(inputs, is_training, relu=True, init_zero=False,\n",
        "                    data_format='channels_first',\n",
        "                    bn_momentum=MOVING_AVERAGE_DECAY):\n",
        "  \"\"\"Performs a batch normalization followed by a ReLU.\n",
        "  Args:\n",
        "    inputs: `Tensor` of shape `[batch, channels, ...]`.\n",
        "    is_training: `bool` for whether the model is training.\n",
        "    relu: `bool` if False, omits the ReLU operation.\n",
        "    init_zero: `bool` if True, initializes scale parameter of batch\n",
        "        normalization with 0 instead of 1 (default).\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "    bn_momentum: `float` momentum for batch norm layer.\n",
        "  Returns:\n",
        "    A normalized `Tensor` with the same `data_format`.\n",
        "  \"\"\"\n",
        "  if init_zero:\n",
        "    gamma_initializer = tf.zeros_initializer()\n",
        "  else:\n",
        "    gamma_initializer = tf.ones_initializer()\n",
        "\n",
        "  if data_format == 'channels_first':\n",
        "    axis = 1\n",
        "  else:\n",
        "    axis = 3\n",
        "\n",
        "  inputs = tf.layers.batch_normalization(\n",
        "      inputs=inputs,\n",
        "      axis=axis,\n",
        "      momentum=bn_momentum,\n",
        "      epsilon=EPSILON,\n",
        "      center=True,\n",
        "      scale=True,\n",
        "      training=is_training,\n",
        "      fused=True,\n",
        "      gamma_initializer=gamma_initializer)\n",
        "\n",
        "  if relu:\n",
        "    inputs = tf.nn.relu(inputs)\n",
        "  return inputs\n",
        "\n",
        "\n",
        "def _instance_std(inputs,\n",
        "                  epsilon=EPSILON,\n",
        "                  data_format='channels_first'):\n",
        "  \"\"\"Instance standard deviation.\"\"\"\n",
        "  axes = [1, 2] if data_format == 'channels_last' else [2, 3]\n",
        "  _, variance = tf.nn.moments(inputs, axes=axes, keepdims=True)\n",
        "  return tf.sqrt(variance + epsilon)\n",
        "\n",
        "\n",
        "def _batch_std(inputs,\n",
        "               training,\n",
        "               decay=MOVING_AVERAGE_DECAY,\n",
        "               epsilon=EPSILON,\n",
        "               data_format='channels_first',\n",
        "               name='moving_variance'):\n",
        "  \"\"\"Batch standard deviation.\"\"\"\n",
        "  if data_format == 'channels_last':\n",
        "    var_shape, axes = (1, 1, 1, inputs.shape[3]), [0, 1, 2]\n",
        "  else:\n",
        "    var_shape, axes = (1, inputs.shape[1], 1, 1), [0, 2, 3]\n",
        "  moving_variance = tf.get_variable(\n",
        "      name=name,\n",
        "      shape=var_shape,\n",
        "      initializer=tf.initializers.ones(),\n",
        "      dtype=tf.float32,\n",
        "      collections=[\n",
        "          tf.GraphKeys.MOVING_AVERAGE_VARIABLES,\n",
        "          tf.GraphKeys.GLOBAL_VARIABLES\n",
        "      ],\n",
        "      trainable=False)\n",
        "  if training:\n",
        "    _, variance = tf.nn.moments(inputs, axes, keep_dims=True)\n",
        "    variance = tf.cast(variance, tf.float32)\n",
        "    update_op = tf.assign_sub(\n",
        "        moving_variance,\n",
        "        (moving_variance - variance) * (1 - decay))\n",
        "    tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_op)\n",
        "  else:\n",
        "    variance = moving_variance\n",
        "  std = tf.sqrt(variance + epsilon)\n",
        "  return tf.cast(std, inputs.dtype)\n",
        "\n",
        "\n",
        "def _get_shape_list(tensor):\n",
        "  \"\"\"Returns tensor's shape as a list which can be unpacked.\"\"\"\n",
        "  static_shape = tensor.shape.as_list()\n",
        "  if not any([x is None for x in static_shape]):\n",
        "    return static_shape\n",
        "\n",
        "  dynamic_shape = tf.shape(tensor)\n",
        "  ndims = tensor.shape.ndims\n",
        "\n",
        "  # Return mixture of static and dynamic dims.\n",
        "  shapes = [\n",
        "      static_shape[i] if static_shape[i] is not None else dynamic_shape[i]\n",
        "      for i in range(ndims)\n",
        "  ]\n",
        "  return shapes\n",
        "\n",
        "\n",
        "def _group_std(inputs,\n",
        "               epsilon=EPSILON,\n",
        "               data_format='channels_first',\n",
        "               num_groups=32):\n",
        "  \"\"\"Grouped standard deviation along the channel dimension.\"\"\"\n",
        "  axis = 3 if data_format == 'channels_last' else 1\n",
        "  while num_groups > 1:\n",
        "    if inputs.shape[axis] % num_groups == 0:\n",
        "      break\n",
        "    num_groups -= 1\n",
        "  if data_format == 'channels_last':\n",
        "    _, h, w, c = inputs.shape.as_list()\n",
        "    x = tf.reshape(inputs, [-1, h, w, num_groups, c // num_groups])\n",
        "    _, variance = tf.nn.moments(x, [1, 2, 4], keep_dims=True)\n",
        "  else:\n",
        "    _, c, h, w = inputs.shape.as_list()\n",
        "    x = tf.reshape(inputs, [-1, num_groups, c // num_groups, h, w])\n",
        "    _, variance = tf.nn.moments(x, [2, 3, 4], keep_dims=True)\n",
        "  std = tf.sqrt(variance + epsilon)\n",
        "  std = tf.broadcast_to(std, _get_shape_list(x))\n",
        "  return tf.reshape(std, _get_shape_list(inputs))\n",
        "\n",
        "\n",
        "def evonorm(inputs,\n",
        "            is_training,\n",
        "            layer=LAYER_EVONORM_B0,\n",
        "            nonlinearity=True,\n",
        "            init_zero=False,\n",
        "            decay=MOVING_AVERAGE_DECAY,\n",
        "            epsilon=EPSILON,\n",
        "            num_groups=32,\n",
        "            data_format='channels_first'):\n",
        "  \"\"\"Apply an EvoNorm transformation (an alternative to BN-ReLU).\n",
        "     Hanxiao Liu, Andrew Brock, Karen Simonyan, Quoc V. Le.\n",
        "     Evolving Normalization-Activation Layers.\n",
        "     https://arxiv.org/abs/2004.02967\n",
        "  Args:\n",
        "    inputs: `Tensor` whose shape is either `[batch, channels, ...]` with\n",
        "        the \"channels_first\" format or `[batch, height, width, channels]`\n",
        "        with the \"channels_last\" format.\n",
        "    is_training: `bool` for whether the model is training.\n",
        "    layer: `String` specifies the EvoNorm instantiation.\n",
        "    nonlinearity: `bool` if False, apply an affine transform only.\n",
        "    init_zero: `bool` if True, initializes scale parameter of batch\n",
        "        normalization with 0 instead of 1 (default).\n",
        "    decay: `float` a scalar decay used in the moving average.\n",
        "    epsilon: `float` a small float added to variance to avoid dividing by zero.\n",
        "    num_groups: `int` the number of groups per layer, used only when `layer` ==\n",
        "        LAYER_EVONORM_S0.\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "  Returns:\n",
        "    A normalized `Tensor` with the same `data_format`.\n",
        "  \"\"\"\n",
        "  if init_zero:\n",
        "    gamma_initializer = tf.zeros_initializer()\n",
        "  else:\n",
        "    gamma_initializer = tf.ones_initializer()\n",
        "\n",
        "  if data_format == 'channels_last':\n",
        "    var_shape = (1, 1, 1, inputs.shape[3])\n",
        "  else:\n",
        "    var_shape = (1, inputs.shape[1], 1, 1)\n",
        "  with tf.variable_scope(None, default_name='evonorm'):\n",
        "    beta = tf.get_variable(\n",
        "        'beta',\n",
        "        shape=var_shape,\n",
        "        dtype=inputs.dtype,\n",
        "        initializer=tf.zeros_initializer())\n",
        "    gamma = tf.get_variable(\n",
        "        'gamma',\n",
        "        shape=var_shape,\n",
        "        dtype=inputs.dtype,\n",
        "        initializer=gamma_initializer)\n",
        "    if nonlinearity:\n",
        "      v = tf.get_variable(\n",
        "          'v',\n",
        "          shape=var_shape,\n",
        "          dtype=inputs.dtype,\n",
        "          initializer=tf.ones_initializer())\n",
        "      if layer == LAYER_EVONORM_S0:\n",
        "        den = _group_std(\n",
        "            inputs,\n",
        "            epsilon=epsilon,\n",
        "            data_format=data_format,\n",
        "            num_groups=num_groups)\n",
        "        inputs = inputs * tf.nn.sigmoid(v * inputs) / den\n",
        "      elif layer == LAYER_EVONORM_B0:\n",
        "        left = _batch_std(\n",
        "            inputs,\n",
        "            decay=decay,\n",
        "            epsilon=epsilon,\n",
        "            data_format=data_format,\n",
        "            training=is_training)\n",
        "        right = v * inputs + _instance_std(\n",
        "            inputs, epsilon=epsilon, data_format=data_format)\n",
        "        inputs = inputs / tf.maximum(left, right)\n",
        "      else:\n",
        "        raise ValueError('Unknown EvoNorm layer: {}'.format(layer))\n",
        "  return inputs * gamma + beta\n",
        "\n",
        "\n",
        "def dropblock(net, is_training, keep_prob, dropblock_size,\n",
        "              data_format='channels_first'):\n",
        "  \"\"\"DropBlock: a regularization method for convolutional neural networks.\n",
        "  DropBlock is a form of structured dropout, where units in a contiguous\n",
        "  region of a feature map are dropped together. DropBlock works better than\n",
        "  dropout on convolutional layers due to the fact that activation units in\n",
        "  convolutional layers are spatially correlated.\n",
        "  See https://arxiv.org/pdf/1810.12890.pdf for details.\n",
        "  Args:\n",
        "    net: `Tensor` input tensor.\n",
        "    is_training: `bool` for whether the model is training.\n",
        "    keep_prob: `float` or `Tensor` keep_prob parameter of DropBlock. \"None\"\n",
        "        means no DropBlock.\n",
        "    dropblock_size: `int` size of blocks to be dropped by DropBlock.\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "  Returns:\n",
        "      A version of input tensor with DropBlock applied.\n",
        "  Raises:\n",
        "      if width and height of the input tensor are not equal.\n",
        "  \"\"\"\n",
        "\n",
        "  if not is_training or keep_prob is None:\n",
        "    return net\n",
        "\n",
        "  tf.logging.info('Applying DropBlock: dropblock_size {}, net.shape {}'.format(\n",
        "      dropblock_size, net.shape))\n",
        "\n",
        "  if data_format == 'channels_last':\n",
        "    _, width, height, _ = net.get_shape().as_list()\n",
        "  else:\n",
        "    _, _, width, height = net.get_shape().as_list()\n",
        "  if width != height:\n",
        "    raise ValueError('Input tensor with width!=height is not supported.')\n",
        "\n",
        "  dropblock_size = min(dropblock_size, width)\n",
        "  # seed_drop_rate is the gamma parameter of DropBlcok.\n",
        "  seed_drop_rate = (1.0 - keep_prob) * width**2 / dropblock_size**2 / (\n",
        "      width - dropblock_size + 1)**2\n",
        "\n",
        "  # Forces the block to be inside the feature map.\n",
        "  w_i, h_i = tf.meshgrid(tf.range(width), tf.range(width))\n",
        "  valid_block_center = tf.logical_and(\n",
        "      tf.logical_and(w_i >= int(dropblock_size // 2),\n",
        "                     w_i < width - (dropblock_size - 1) // 2),\n",
        "      tf.logical_and(h_i >= int(dropblock_size // 2),\n",
        "                     h_i < width - (dropblock_size - 1) // 2))\n",
        "\n",
        "  valid_block_center = tf.expand_dims(valid_block_center, 0)\n",
        "  valid_block_center = tf.expand_dims(\n",
        "      valid_block_center, -1 if data_format == 'channels_last' else 0)\n",
        "\n",
        "  randnoise = tf.random_uniform(net.shape, dtype=tf.float32)\n",
        "  block_pattern = (1 - tf.cast(valid_block_center, dtype=tf.float32) + tf.cast(\n",
        "      (1 - seed_drop_rate), dtype=tf.float32) + randnoise) >= 1\n",
        "  block_pattern = tf.cast(block_pattern, dtype=tf.float32)\n",
        "\n",
        "  if dropblock_size == width:\n",
        "    block_pattern = tf.reduce_min(\n",
        "        block_pattern,\n",
        "        axis=[1, 2] if data_format == 'channels_last' else [2, 3],\n",
        "        keepdims=True)\n",
        "  else:\n",
        "    if data_format == 'channels_last':\n",
        "      ksize = [1, dropblock_size, dropblock_size, 1]\n",
        "    else:\n",
        "      ksize = [1, 1, dropblock_size, dropblock_size]\n",
        "    block_pattern = -tf.nn.max_pool(\n",
        "        -block_pattern, ksize=ksize, strides=[1, 1, 1, 1], padding='SAME',\n",
        "        data_format='NHWC' if data_format == 'channels_last' else 'NCHW')\n",
        "\n",
        "  percent_ones = tf.cast(tf.reduce_sum((block_pattern)), tf.float32) / tf.cast(\n",
        "      tf.size(block_pattern), tf.float32)\n",
        "\n",
        "  net = net / tf.cast(percent_ones, net.dtype) * tf.cast(\n",
        "      block_pattern, net.dtype)\n",
        "  return net\n",
        "\n",
        "\n",
        "def fixed_padding(inputs, kernel_size, data_format='channels_first'):\n",
        "  \"\"\"Pads the input along the spatial dimensions independently of input size.\n",
        "  Args:\n",
        "    inputs: `Tensor` of size `[batch, channels, height, width]` or\n",
        "        `[batch, height, width, channels]` depending on `data_format`.\n",
        "    kernel_size: `int` kernel size to be used for `conv2d` or max_pool2d`\n",
        "        operations. Should be a positive integer.\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "  Returns:\n",
        "    A padded `Tensor` of the same `data_format` with size either intact\n",
        "    (if `kernel_size == 1`) or padded (if `kernel_size > 1`).\n",
        "  \"\"\"\n",
        "  pad_total = kernel_size - 1\n",
        "  pad_beg = pad_total // 2\n",
        "  pad_end = pad_total - pad_beg\n",
        "  if data_format == 'channels_first':\n",
        "    padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
        "                                    [pad_beg, pad_end], [pad_beg, pad_end]])\n",
        "  else:\n",
        "    padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
        "                                    [pad_beg, pad_end], [0, 0]])\n",
        "\n",
        "  return padded_inputs\n",
        "\n",
        "\n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, strides,\n",
        "                         data_format='channels_first'):\n",
        "  \"\"\"Strided 2-D convolution with explicit padding.\n",
        "  The padding is consistent and is based only on `kernel_size`, not on the\n",
        "  dimensions of `inputs` (as opposed to using `tf.layers.conv2d` alone).\n",
        "  Args:\n",
        "    inputs: `Tensor` of size `[batch, channels, height_in, width_in]`.\n",
        "    filters: `int` number of filters in the convolution.\n",
        "    kernel_size: `int` size of the kernel to be used in the convolution.\n",
        "    strides: `int` strides of the convolution.\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "  Returns:\n",
        "    A `Tensor` of shape `[batch, filters, height_out, width_out]`.\n",
        "  \"\"\"\n",
        "  if strides > 1:\n",
        "    inputs = fixed_padding(inputs, kernel_size, data_format=data_format)\n",
        "\n",
        "  return tf.layers.conv2d(\n",
        "      inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,\n",
        "      padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,\n",
        "      kernel_initializer=tf.variance_scaling_initializer(),\n",
        "      data_format=data_format)\n",
        "\n",
        "\n",
        "def residual_block(inputs, filters, is_training, strides,\n",
        "                   use_projection=False, data_format='channels_first',\n",
        "                   dropblock_keep_prob=None, dropblock_size=None,\n",
        "                   pre_activation=False, norm_act_layer=LAYER_BN_RELU,\n",
        "                   resnetd_shortcut=False, se_ratio=None,\n",
        "                   drop_connect_rate=None, bn_momentum=MOVING_AVERAGE_DECAY):\n",
        "  \"\"\"Standard building block for residual networks with BN after convolutions.\n",
        "  Args:\n",
        "    inputs: `Tensor` of size `[batch, channels, height, width]`.\n",
        "    filters: `int` number of filters for the first two convolutions. Note that\n",
        "        the third and final convolution will use 4 times as many filters.\n",
        "    is_training: `bool` for whether the model is in training.\n",
        "    strides: `int` block stride. If greater than 1, this block will ultimately\n",
        "        downsample the input.\n",
        "    use_projection: `bool` for whether this block should use a projection\n",
        "        shortcut (versus the default identity shortcut). This is usually `True`\n",
        "        for the first block of a block group, which may change the number of\n",
        "        filters and the resolution.\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "    dropblock_keep_prob: unused; needed to give method same signature as other\n",
        "      blocks\n",
        "    dropblock_size: unused; needed to give method same signature as other\n",
        "      blocks\n",
        "    pre_activation: whether to use pre-activation ResNet (ResNet-v2).\n",
        "    norm_act_layer: name of the normalization-activation layer.\n",
        "    resnetd_shortcut: `bool` if True, apply the resnetd style modification to\n",
        "        the shortcut connection.\n",
        "    se_ratio: `float` or None. Squeeze-and-Excitation ratio for the SE layer.\n",
        "    drop_connect_rate: `float` or None. Drop connect rate for this block.\n",
        "    bn_momentum: `float` momentum for batch norm layer.\n",
        "  Returns:\n",
        "    The output `Tensor` of the block.\n",
        "  \"\"\"\n",
        "  del dropblock_keep_prob\n",
        "  del dropblock_size\n",
        "  del resnetd_shortcut\n",
        "  del se_ratio\n",
        "  del drop_connect_rate\n",
        "\n",
        "  shortcut = inputs\n",
        "  if pre_activation:\n",
        "    inputs = norm_activation(inputs, is_training, data_format=data_format,\n",
        "                             layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "  if use_projection:\n",
        "    # Projection shortcut in first layer to match filters and strides\n",
        "    shortcut = conv2d_fixed_padding(\n",
        "        inputs=inputs, filters=filters, kernel_size=1, strides=strides,\n",
        "        data_format=data_format)\n",
        "    if not pre_activation:\n",
        "      shortcut = norm_activation(\n",
        "          shortcut, is_training, nonlinearity=False, data_format=data_format,\n",
        "          layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "  inputs = norm_activation(inputs, is_training, data_format=data_format,\n",
        "                           layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=1,\n",
        "      data_format=data_format)\n",
        "  if pre_activation:\n",
        "    return inputs + shortcut\n",
        "  else:\n",
        "    inputs = norm_activation(\n",
        "        inputs, is_training, nonlinearity=False, init_zero=True,\n",
        "        data_format=data_format, layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "\n",
        "    return tf.nn.relu(inputs + shortcut)\n",
        "\n",
        "\n",
        "def bottleneck_block(inputs, filters, is_training, strides,\n",
        "                     use_projection=False, data_format='channels_first',\n",
        "                     dropblock_keep_prob=None, dropblock_size=None,\n",
        "                     pre_activation=False, norm_act_layer=LAYER_BN_RELU,\n",
        "                     resnetd_shortcut=False, se_ratio=None,\n",
        "                     drop_connect_rate=None, bn_momentum=MOVING_AVERAGE_DECAY):\n",
        "  \"\"\"Bottleneck block variant for residual networks with BN after convolutions.\n",
        "  Args:\n",
        "    inputs: `Tensor` of size `[batch, channels, height, width]`.\n",
        "    filters: `int` number of filters for the first two convolutions. Note that\n",
        "        the third and final convolution will use 4 times as many filters.\n",
        "    is_training: `bool` for whether the model is in training.\n",
        "    strides: `int` block stride. If greater than 1, this block will ultimately\n",
        "        downsample the input.\n",
        "    use_projection: `bool` for whether this block should use a projection\n",
        "        shortcut (versus the default identity shortcut). This is usually `True`\n",
        "        for the first block of a block group, which may change the number of\n",
        "        filters and the resolution.\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "    dropblock_keep_prob: `float` or `Tensor` keep_prob parameter of DropBlock.\n",
        "        \"None\" means no DropBlock.\n",
        "    dropblock_size: `int` size parameter of DropBlock. Will not be used if\n",
        "        dropblock_keep_prob is \"None\".\n",
        "    pre_activation: whether to use pre-activation ResNet (ResNet-v2).\n",
        "    norm_act_layer: name of the normalization-activation layer.\n",
        "    resnetd_shortcut: `bool` if True, apply the resnetd style modification to\n",
        "        the shortcut connection.\n",
        "    se_ratio: `float` or None. Squeeze-and-Excitation ratio for the SE layer.\n",
        "    drop_connect_rate: `float` or None. Drop connect rate for this block.\n",
        "    bn_momentum: `float` momentum for batch norm layer.\n",
        "  Returns:\n",
        "    The output `Tensor` of the block.\n",
        "  \"\"\"\n",
        "  shortcut = inputs\n",
        "  if pre_activation:\n",
        "    inputs = norm_activation(inputs, is_training, data_format=data_format,\n",
        "                             layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "  if use_projection:\n",
        "    # Projection shortcut only in first block within a group. Bottleneck blocks\n",
        "    # end with 4 times the number of filters.\n",
        "    filters_out = 4 * filters\n",
        "    if resnetd_shortcut and strides == 2:\n",
        "      shortcut = tf.keras.layers.AveragePooling2D(\n",
        "          pool_size=(2, 2), strides=(2, 2), padding='same',\n",
        "          data_format=data_format)(inputs)\n",
        "      shortcut = conv2d_fixed_padding(\n",
        "          inputs=shortcut, filters=filters_out, kernel_size=1, strides=1,\n",
        "          data_format=data_format)\n",
        "    else:\n",
        "      shortcut = conv2d_fixed_padding(\n",
        "          inputs=inputs, filters=filters_out, kernel_size=1, strides=strides,\n",
        "          data_format=data_format)\n",
        "\n",
        "    if not pre_activation:\n",
        "      shortcut = norm_activation(\n",
        "          shortcut, is_training, nonlinearity=False,\n",
        "          data_format=data_format, layer=norm_act_layer,\n",
        "          bn_momentum=bn_momentum)\n",
        "  shortcut = dropblock(\n",
        "      shortcut, is_training=is_training, data_format=data_format,\n",
        "      keep_prob=dropblock_keep_prob, dropblock_size=dropblock_size)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "  inputs = norm_activation(inputs, is_training, data_format=data_format,\n",
        "                           layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "  inputs = dropblock(\n",
        "      inputs, is_training=is_training, data_format=data_format,\n",
        "      keep_prob=dropblock_keep_prob, dropblock_size=dropblock_size)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "  inputs = norm_activation(inputs, is_training, data_format=data_format,\n",
        "                           layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "  inputs = dropblock(\n",
        "      inputs, is_training=is_training, data_format=data_format,\n",
        "      keep_prob=dropblock_keep_prob, dropblock_size=dropblock_size)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "\n",
        "  if pre_activation:\n",
        "    return inputs + shortcut\n",
        "  else:\n",
        "    inputs = norm_activation(inputs, is_training, nonlinearity=False,\n",
        "                             init_zero=True, data_format=data_format,\n",
        "                             layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "    inputs = dropblock(\n",
        "        inputs, is_training=is_training, data_format=data_format,\n",
        "        keep_prob=dropblock_keep_prob, dropblock_size=dropblock_size)\n",
        "\n",
        "    if se_ratio is not None and se_ratio > 0 and se_ratio <= 1:\n",
        "      inputs = resnet_layers.squeeze_excitation(\n",
        "          inputs, in_filters=4 * filters,\n",
        "          se_ratio=se_ratio, data_format='channels_last')\n",
        "\n",
        "    if drop_connect_rate is not None:\n",
        "      tf.logging.info('using drop_connect: {}'.format(drop_connect_rate))\n",
        "      inputs = resnet_layers.drop_connect(\n",
        "          inputs, is_training, drop_connect_rate)\n",
        "\n",
        "    return tf.nn.relu(inputs + shortcut)\n",
        "\n",
        "\n",
        "def block_group(inputs, filters, block_fn, blocks, strides, is_training, name,\n",
        "                data_format='channels_first', dropblock_keep_prob=None,\n",
        "                dropblock_size=None, pre_activation=False,\n",
        "                norm_act_layer=LAYER_BN_RELU, se_ratio=None,\n",
        "                resnetd_shortcut=False, drop_connect_rate=None,\n",
        "                bn_momentum=MOVING_AVERAGE_DECAY):\n",
        "  \"\"\"Creates one group of blocks for the ResNet model.\n",
        "  Args:\n",
        "    inputs: `Tensor` of size `[batch, channels, height, width]`.\n",
        "    filters: `int` number of filters for the first convolution of the layer.\n",
        "    block_fn: `function` for the block to use within the model\n",
        "    blocks: `int` number of blocks contained in the layer.\n",
        "    strides: `int` stride to use for the first convolution of the layer. If\n",
        "        greater than 1, this layer will downsample the input.\n",
        "    is_training: `bool` for whether the model is training.\n",
        "    name: `str`name for the Tensor output of the block layer.\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "    dropblock_keep_prob: `float` or `Tensor` keep_prob parameter of DropBlock.\n",
        "        \"None\" means no DropBlock.\n",
        "    dropblock_size: `int` size parameter of DropBlock. Will not be used if\n",
        "        dropblock_keep_prob is \"None\".\n",
        "    pre_activation: whether to use pre-activation ResNet (ResNet-v2).\n",
        "    norm_act_layer: name of the normalization-activation layer.\n",
        "    se_ratio: `float` or None. Squeeze-and-Excitation ratio for the SE layer.\n",
        "    resnetd_shortcut: `bool` if True, apply the resnetd style modification to\n",
        "        the shortcut connection in downsampling blocks.\n",
        "    drop_connect_rate: `float` or None. Drop connect rate for this block.\n",
        "    bn_momentum: `float` momentum for batch norm layer.\n",
        "  Returns:\n",
        "    The output `Tensor` of the block layer.\n",
        "  \"\"\"\n",
        "  # Only the first block per block_group uses projection shortcut and strides.\n",
        "  inputs = block_fn(inputs, filters, is_training, strides,\n",
        "                    use_projection=True, data_format=data_format,\n",
        "                    dropblock_keep_prob=dropblock_keep_prob,\n",
        "                    dropblock_size=dropblock_size,\n",
        "                    pre_activation=pre_activation,\n",
        "                    norm_act_layer=norm_act_layer,\n",
        "                    se_ratio=se_ratio,\n",
        "                    resnetd_shortcut=resnetd_shortcut,\n",
        "                    drop_connect_rate=drop_connect_rate,\n",
        "                    bn_momentum=bn_momentum)\n",
        "\n",
        "  for _ in range(1, blocks):\n",
        "    inputs = block_fn(inputs, filters, is_training, 1,\n",
        "                      data_format=data_format,\n",
        "                      dropblock_keep_prob=dropblock_keep_prob,\n",
        "                      dropblock_size=dropblock_size,\n",
        "                      pre_activation=pre_activation,\n",
        "                      norm_act_layer=norm_act_layer,\n",
        "                      se_ratio=se_ratio,\n",
        "                      resnetd_shortcut=resnetd_shortcut,\n",
        "                      drop_connect_rate=drop_connect_rate,\n",
        "                      bn_momentum=bn_momentum)\n",
        "\n",
        "  return tf.identity(inputs, name)\n",
        "\n",
        "\n",
        "def resnet_generator(block_fn,\n",
        "                     layers,\n",
        "                     num_classes,\n",
        "                     data_format='channels_first',\n",
        "                     use_resnetd_stem=False,\n",
        "                     resnetd_shortcut=False,\n",
        "                     replace_stem_max_pool=False,\n",
        "                     skip_stem_max_pool=False,\n",
        "                     drop_connect_rate=None,\n",
        "                     se_ratio=None,\n",
        "                     dropout_rate=None,\n",
        "                     dropblock_keep_probs=None,\n",
        "                     dropblock_size=None,\n",
        "                     pre_activation=False,\n",
        "                     norm_act_layer=LAYER_BN_RELU,\n",
        "                     bn_momentum=MOVING_AVERAGE_DECAY):\n",
        "  \"\"\"Generator for ResNet models.\n",
        "  Args:\n",
        "    block_fn: `function` for the block to use within the model. Either\n",
        "        `residual_block` or `bottleneck_block`.\n",
        "    layers: list of 4 `int`s denoting the number of blocks to include in each\n",
        "      of the 4 block groups. Each group consists of blocks that take inputs of\n",
        "      the same resolution.\n",
        "    num_classes: `int` number of possible classes for image classification.\n",
        "    data_format: `str` either \"channels_first\" for `[batch, channels, height,\n",
        "        width]` or \"channels_last for `[batch, height, width, channels]`.\n",
        "    use_resnetd_stem: `bool` whether to use ResNet-D stem.\n",
        "    resnetd_shortcut: `bool` whether to use ResNet-D shortcut in blocks.\n",
        "    replace_stem_max_pool: `bool` if True, replace the max pool in stem with\n",
        "        a stride-2 conv,\n",
        "    skip_stem_max_pool: `bool` if True, skip the max pool in stem and set the\n",
        "        stride of the following block to 2,\n",
        "    drop_connect_rate: `float` initial rate for drop-connect.\n",
        "    se_ratio: `float` Squeeze-and-Excitation ratio for SE layers.\n",
        "    dropout_rate: `float` drop rate for the dropout layer.\n",
        "    dropblock_keep_probs: `list` of 4 elements denoting keep_prob of DropBlock\n",
        "      for each block group. None indicates no DropBlock for the corresponding\n",
        "      block group.\n",
        "    dropblock_size: `int`: size parameter of DropBlock.\n",
        "    pre_activation: whether to use pre-activation ResNet (ResNet-v2).\n",
        "    norm_act_layer: name of the normalization-activation layer.\n",
        "    bn_momentum: `float` momentum for batch norm layer.\n",
        "  Returns:\n",
        "    Model `function` that takes in `inputs` and `is_training` and returns the\n",
        "    output `Tensor` of the ResNet model.\n",
        "  Raises:\n",
        "    if dropblock_keep_probs is not 'None' or a list with len 4.\n",
        "  \"\"\"\n",
        "  if dropblock_keep_probs is None:\n",
        "    dropblock_keep_probs = [None] * 4\n",
        "  if not isinstance(dropblock_keep_probs,\n",
        "                    list) or len(dropblock_keep_probs) != 4:\n",
        "    raise ValueError('dropblock_keep_probs is not valid:', dropblock_keep_probs)\n",
        "\n",
        "  def model(inputs, is_training):\n",
        "    \"\"\"Creation of the model graph.\"\"\"\n",
        "    if use_resnetd_stem:\n",
        "      inputs = conv2d_fixed_padding(\n",
        "          inputs=inputs, filters=32, kernel_size=3, strides=2,\n",
        "          data_format=data_format)\n",
        "      inputs = norm_activation(\n",
        "          inputs, is_training, data_format=data_format,\n",
        "          layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "      inputs = conv2d_fixed_padding(\n",
        "          inputs=inputs, filters=32, kernel_size=3, strides=1,\n",
        "          data_format=data_format)\n",
        "      inputs = norm_activation(\n",
        "          inputs, is_training, data_format=data_format,\n",
        "          layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "      inputs = conv2d_fixed_padding(\n",
        "          inputs=inputs, filters=64, kernel_size=3, strides=1,\n",
        "          data_format=data_format)\n",
        "    else:\n",
        "      inputs = conv2d_fixed_padding(\n",
        "          inputs=inputs, filters=64, kernel_size=7, strides=2,\n",
        "          data_format=data_format)\n",
        "\n",
        "    inputs = tf.identity(inputs, 'initial_conv')\n",
        "    if not pre_activation:\n",
        "      inputs = norm_activation(inputs, is_training, data_format=data_format,\n",
        "                               layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "\n",
        "    if not skip_stem_max_pool:\n",
        "      if replace_stem_max_pool:\n",
        "        inputs = conv2d_fixed_padding(\n",
        "            inputs=inputs, filters=64,\n",
        "            kernel_size=3, strides=2, data_format=data_format)\n",
        "        inputs = norm_activation(\n",
        "            inputs, is_training, data_format=data_format,\n",
        "            bn_momentum=bn_momentum)\n",
        "      else:\n",
        "        inputs = tf.layers.max_pooling2d(\n",
        "            inputs=inputs, pool_size=3, strides=2, padding='SAME',\n",
        "            data_format=data_format)\n",
        "        inputs = tf.identity(inputs, 'initial_max_pool')\n",
        "\n",
        "    custom_block_group = functools.partial(\n",
        "        block_group,\n",
        "        data_format=data_format,\n",
        "        dropblock_size=dropblock_size,\n",
        "        pre_activation=pre_activation,\n",
        "        norm_act_layer=norm_act_layer,\n",
        "        se_ratio=se_ratio,\n",
        "        resnetd_shortcut=resnetd_shortcut,\n",
        "        bn_momentum=bn_momentum)\n",
        "\n",
        "    num_layers = len(layers) + 1\n",
        "    stride_c2 = 2 if skip_stem_max_pool else 1\n",
        "\n",
        "    inputs = custom_block_group(\n",
        "        inputs=inputs, filters=64, block_fn=block_fn, blocks=layers[0],\n",
        "        strides=stride_c2, is_training=is_training, name='block_group1',\n",
        "        dropblock_keep_prob=dropblock_keep_probs[0],\n",
        "        drop_connect_rate=resnet_layers.get_drop_connect_rate(\n",
        "            drop_connect_rate, 2, num_layers))\n",
        "    inputs = custom_block_group(\n",
        "        inputs=inputs, filters=128, block_fn=block_fn, blocks=layers[1],\n",
        "        strides=2, is_training=is_training, name='block_group2',\n",
        "        dropblock_keep_prob=dropblock_keep_probs[1],\n",
        "        drop_connect_rate=resnet_layers.get_drop_connect_rate(\n",
        "            drop_connect_rate, 3, num_layers))\n",
        "    inputs = custom_block_group(\n",
        "        inputs=inputs, filters=256, block_fn=block_fn, blocks=layers[2],\n",
        "        strides=2, is_training=is_training, name='block_group3',\n",
        "        dropblock_keep_prob=dropblock_keep_probs[2],\n",
        "        drop_connect_rate=resnet_layers.get_drop_connect_rate(\n",
        "            drop_connect_rate, 4, num_layers))\n",
        "    inputs = custom_block_group(\n",
        "        inputs=inputs, filters=512, block_fn=block_fn, blocks=layers[3],\n",
        "        strides=2, is_training=is_training, name='block_group4',\n",
        "        dropblock_keep_prob=dropblock_keep_probs[3],\n",
        "        drop_connect_rate=resnet_layers.get_drop_connect_rate(\n",
        "            drop_connect_rate, 5, num_layers))\n",
        "\n",
        "    if pre_activation:\n",
        "      inputs = norm_activation(inputs, is_training, data_format=data_format,\n",
        "                               layer=norm_act_layer, bn_momentum=bn_momentum)\n",
        "\n",
        "    # The activation is 7x7 so this is a global average pool.\n",
        "    # TODO(huangyp): reduce_mean will be faster.\n",
        "    if data_format == 'channels_last':\n",
        "      pool_size = (inputs.shape[1], inputs.shape[2])\n",
        "    else:\n",
        "      pool_size = (inputs.shape[2], inputs.shape[3])\n",
        "    inputs = tf.layers.average_pooling2d(\n",
        "        inputs=inputs, pool_size=pool_size, strides=1, padding='VALID',\n",
        "        data_format=data_format)\n",
        "    inputs = tf.identity(inputs, 'final_avg_pool')\n",
        "    inputs = tf.reshape(\n",
        "        inputs, [-1, 2048 if block_fn is bottleneck_block else 512])\n",
        "\n",
        "    if dropout_rate is not None:\n",
        "      tf.logging.info('using dropout')\n",
        "      inputs = tf.layers.dropout(\n",
        "          inputs, rate=dropout_rate, training=is_training)\n",
        "\n",
        "    inputs = tf.layers.dense(\n",
        "        inputs=inputs,\n",
        "        units=num_classes,\n",
        "        kernel_initializer=tf.random_normal_initializer(stddev=.01))\n",
        "    inputs = tf.identity(inputs, 'final_dense')\n",
        "    return inputs\n",
        "\n",
        "  model.default_image_size = 224\n",
        "  return model\n",
        "\n",
        "\n",
        "def resnet(resnet_depth, num_classes, data_format='channels_first',\n",
        "           dropblock_keep_probs=None, dropblock_size=None,\n",
        "           pre_activation=False, norm_act_layer=LAYER_BN_RELU,\n",
        "           se_ratio=None, drop_connect_rate=None, use_resnetd_stem=False,\n",
        "           resnetd_shortcut=False, skip_stem_max_pool=False,\n",
        "           replace_stem_max_pool=False, dropout_rate=None,\n",
        "           bn_momentum=MOVING_AVERAGE_DECAY):\n",
        "  \"\"\"Returns the ResNet model for a given size and number of output classes.\"\"\"\n",
        "  model_params = {\n",
        "      18: {'block': residual_block, 'layers': [2, 2, 2, 2]},\n",
        "      34: {'block': residual_block, 'layers': [3, 4, 6, 3]},\n",
        "      50: {'block': bottleneck_block, 'layers': [3, 4, 6, 3]},\n",
        "      101: {'block': bottleneck_block, 'layers': [3, 4, 23, 3]},\n",
        "      152: {'block': bottleneck_block, 'layers': [3, 8, 36, 3]},\n",
        "      200: {'block': bottleneck_block, 'layers': [3, 24, 36, 3]},\n",
        "      270: {'block': bottleneck_block, 'layers': [4, 29, 53, 4]},\n",
        "      350: {'block': bottleneck_block, 'layers': [4, 36, 72, 4]},\n",
        "      420: {'block': bottleneck_block, 'layers': [4, 44, 87, 4]}\n",
        "  }\n",
        "\n",
        "  if resnet_depth not in model_params:\n",
        "    raise ValueError('Not a valid resnet_depth:', resnet_depth)\n",
        "\n",
        "  if norm_act_layer in LAYER_EVONORMS and not pre_activation:\n",
        "    raise ValueError('Evonorms require the pre-activation form.')\n",
        "\n",
        "  params = model_params[resnet_depth]\n",
        "  return resnet_generator(\n",
        "      params['block'], params['layers'], num_classes,\n",
        "      dropblock_keep_probs=dropblock_keep_probs,\n",
        "      dropblock_size=dropblock_size,\n",
        "      data_format=data_format,\n",
        "      pre_activation=pre_activation,\n",
        "      norm_act_layer=norm_act_layer,\n",
        "      use_resnetd_stem=use_resnetd_stem,\n",
        "      resnetd_shortcut=resnetd_shortcut,\n",
        "      se_ratio=se_ratio,\n",
        "      drop_connect_rate=drop_connect_rate,\n",
        "      dropout_rate=dropout_rate,\n",
        "      skip_stem_max_pool=skip_stem_max_pool,\n",
        "      replace_stem_max_pool=replace_stem_max_pool,\n",
        "      bn_momentum=bn_momentum)\n",
        "\n",
        "\n",
        "resnet_v1 = functools.partial(resnet, pre_activation=False)\n",
        "resnet_v2 = functools.partial(resnet, pre_activation=True)\n",
        "resnet_v1_generator = functools.partial(resnet_generator, pre_activation=False)\n",
        "resnet_v2_generator = functools.partial(resnet_generator, pre_activation=True)"
      ]
    }
  ]
}