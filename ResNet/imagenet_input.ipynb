{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imagenet_input.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4Rsjd9GJ5LMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a79cb7-96a1-400a-ebea-d693ac065f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.1 MB/s \n",
            "\u001b[?25himporting Jupyter notebook from /nbs/resnet_preprocessing.ipynb\n"
          ]
        }
      ],
      "source": [
        "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Efficient ImageNet input pipeline using tf.data.Dataset.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import collections\n",
        "import functools\n",
        "import os\n",
        "from absl import logging\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow.compat.v1 import estimator as tf_estimator\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "''' import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/Important/6th sem/ML_paper/Codes/resnet_preprocessing.ipynb')\n",
        "import resnet_preprocessing '''\n",
        "!pip install kora -q\n",
        "from kora import drive\n",
        "drive.link_nbs()\n",
        "\n",
        "import resnet_preprocessing\n",
        "\n",
        "def image_serving_input_fn():\n",
        "  \"\"\"Serving input fn for raw images.\"\"\"\n",
        "\n",
        "  def _preprocess_image(image_bytes):\n",
        "    \"\"\"Preprocess a single raw image.\"\"\"\n",
        "    image = resnet_preprocessing.preprocess_image(\n",
        "        image_bytes=image_bytes, is_training=False)\n",
        "    return image\n",
        "\n",
        "  image_bytes_list = tf.placeholder(\n",
        "      shape=[None],\n",
        "      dtype=tf.string,\n",
        "  )\n",
        "  images = tf.map_fn(\n",
        "      _preprocess_image, image_bytes_list, back_prop=False, dtype=tf.float32)\n",
        "  return tf_estimator.export.TensorServingInputReceiver(\n",
        "      features=images, receiver_tensors=image_bytes_list)\n",
        "\n",
        "\n",
        "class ImageNetTFExampleInput(object):\n",
        "  \"\"\"Base class for ImageNet input_fn generator.\n",
        "  Attributes:\n",
        "    image_preprocessing_fn: function to preprocess images\n",
        "    is_training: `bool` for whether the input is for training\n",
        "    use_bfloat16: If True, use bfloat16 precision; else use float32.\n",
        "    transpose_input: 'bool' for whether to use the double transpose trick\n",
        "    image_size: size of images\n",
        "    num_parallel_calls: `int` for the number of parallel threads.\n",
        "    include_background_label: `bool` for whether to include the background label\n",
        "    augment_name: `string` that is the name of the augmentation method\n",
        "        to apply to the image. `autoaugment` if AutoAugment is to be used or\n",
        "        `randaugment` if RandAugment is to be used. If the value is `None` no\n",
        "        no augmentation method will be applied applied. See autoaugment.py\n",
        "        for more details.\n",
        "    randaug_num_layers: 'int', if RandAug is used, what should the number of\n",
        "      layers be. See autoaugment.py for detailed description.\n",
        "    randaug_magnitude: 'int', if RandAug is used, what should the magnitude\n",
        "      be. See autoaugment.py for detailed description.\n",
        "  \"\"\"\n",
        "  __metaclass__ = abc.ABCMeta\n",
        "\n",
        "  def __init__(self,\n",
        "               is_training,\n",
        "               use_bfloat16,\n",
        "               image_size=224,\n",
        "               transpose_input=False,\n",
        "               num_parallel_calls=8,\n",
        "               include_background_label=False,\n",
        "               augment_name=None,\n",
        "               randaug_num_layers=None,\n",
        "               randaug_magnitude=None):\n",
        "    self.image_preprocessing_fn = resnet_preprocessing.preprocess_image\n",
        "    self.is_training = is_training\n",
        "    self.use_bfloat16 = use_bfloat16\n",
        "    self.transpose_input = transpose_input\n",
        "    self.image_size = image_size\n",
        "    self.num_parallel_calls = num_parallel_calls\n",
        "    self.include_background_label = include_background_label\n",
        "    self.augment_name = augment_name\n",
        "    self.randaug_num_layers = randaug_num_layers\n",
        "    self.randaug_magnitude = randaug_magnitude\n",
        "\n",
        "  def set_shapes(self, batch_size, images, labels):\n",
        "    \"\"\"Statically set the batch_size dimension.\"\"\"\n",
        "    if self.transpose_input:\n",
        "      images.set_shape(images.get_shape().merge_with(\n",
        "          tf.TensorShape([None, None, None, batch_size])))\n",
        "      images = tf.reshape(images, [-1])\n",
        "      labels.set_shape(labels.get_shape().merge_with(\n",
        "          tf.TensorShape([batch_size])))\n",
        "    else:\n",
        "      images.set_shape(images.get_shape().merge_with(\n",
        "          tf.TensorShape([batch_size, None, None, None])))\n",
        "      labels.set_shape(labels.get_shape().merge_with(\n",
        "          tf.TensorShape([batch_size])))\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "  def dataset_parser(self, value):\n",
        "    \"\"\"Parses an image and its label from a serialized ResNet-50 TFExample.\n",
        "    Args:\n",
        "      value: serialized string containing an ImageNet TFExample.\n",
        "    Returns:\n",
        "      Returns a tuple of (image, label) from the TFExample.\n",
        "    \"\"\"\n",
        "    keys_to_features = {\n",
        "        'image/encoded': tf.FixedLenFeature((), tf.string, ''),\n",
        "        'image/class/label': tf.FixedLenFeature([], tf.int64, -1),\n",
        "    }\n",
        "\n",
        "    parsed = tf.parse_single_example(value, keys_to_features)\n",
        "    image_bytes = tf.reshape(parsed['image/encoded'], shape=[])\n",
        "\n",
        "    image = self.image_preprocessing_fn(\n",
        "        image_bytes=image_bytes,\n",
        "        is_training=self.is_training,\n",
        "        image_size=self.image_size,\n",
        "        use_bfloat16=self.use_bfloat16,\n",
        "        augment_name=self.augment_name,\n",
        "        randaug_num_layers=self.randaug_num_layers,\n",
        "        randaug_magnitude=self.randaug_magnitude)\n",
        "\n",
        "    label = tf.cast(\n",
        "        tf.reshape(parsed['image/class/label'], shape=[]), dtype=tf.int32)\n",
        "\n",
        "    if not self.include_background_label:\n",
        "      # 'image/class/label' is encoded as an integer from 1 to num_label_classes\n",
        "      # In order to generate the correct one-hot label vector from this number,\n",
        "      # we subtract the number by 1 to make it in [0, num_label_classes).\n",
        "      label -= 1\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def make_source_dataset(self, index, num_hosts):\n",
        "    \"\"\"Makes dataset of serialized TFExamples.\n",
        "    The returned dataset will contain `tf.string` tensors, but these strings are\n",
        "    serialized `TFExample` records that will be parsed by `dataset_parser`.\n",
        "    If self.is_training, the dataset should be infinite.\n",
        "    Args:\n",
        "      index: current host index.\n",
        "      num_hosts: total number of hosts.\n",
        "    Returns:\n",
        "      A `tf.data.Dataset` object.\n",
        "    \"\"\"\n",
        "    return\n",
        "\n",
        "  def input_fn(self, params):\n",
        "    \"\"\"Input function which provides a single batch for train or eval.\n",
        "    Args:\n",
        "      params: `dict` of parameters passed from the `TPUEstimator`.\n",
        "        `params['batch_size']` is always provided and should be used as the\n",
        "        effective batch size.\n",
        "    Returns:\n",
        "      A `tf.data.Dataset` object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieves the batch size for the current shard. The # of shards is\n",
        "    # computed according to the input pipeline deployment. See\n",
        "    # tf.estimator.tpu.RunConfig for details.\n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    # TODO(dehao): Replace the following with params['context'].current_host\n",
        "    if 'context' in params:\n",
        "      current_host = params['context'].current_input_fn_deployment()[1]\n",
        "      num_hosts = params['context'].num_hosts\n",
        "    else:\n",
        "      current_host = 0\n",
        "      num_hosts = 1\n",
        "\n",
        "    dataset = self.make_source_dataset(current_host, num_hosts)\n",
        "\n",
        "    # Use the fused map-and-batch operation.\n",
        "    #\n",
        "    # For XLA, we must used fixed shapes. Because we repeat the source training\n",
        "    # dataset indefinitely, we can use `drop_remainder=True` to get fixed-size\n",
        "    # batches without dropping any training examples.\n",
        "    #\n",
        "    # When evaluating, `drop_remainder=True` prevents accidentally evaluating\n",
        "    # the same image twice by dropping the final batch if it is less than a full\n",
        "    # batch size. As long as this validation is done with consistent batch size,\n",
        "    # exactly the same images will be used.\n",
        "    dataset = dataset.apply(\n",
        "        tf.data.experimental.map_and_batch(\n",
        "            self.dataset_parser,\n",
        "            batch_size=batch_size,\n",
        "            num_parallel_batches=self.num_parallel_calls,\n",
        "            drop_remainder=True))\n",
        "\n",
        "    # Transpose for performance on TPU\n",
        "    if self.transpose_input:\n",
        "      dataset = dataset.map(\n",
        "          lambda images, labels: (tf.transpose(images, [1, 2, 3, 0]), labels),\n",
        "          num_parallel_calls=self.num_parallel_calls)\n",
        "\n",
        "    # Assign static batch size dimension\n",
        "    dataset = dataset.map(functools.partial(self.set_shapes, batch_size))\n",
        "\n",
        "    # Prefetch overlaps in-feed with training\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "class ImageNetInput(ImageNetTFExampleInput):\n",
        "  \"\"\"Generates ImageNet input_fn from a series of TFRecord files.\n",
        "  The training data is assumed to be in TFRecord format with keys as specified\n",
        "  in the dataset_parser below, sharded across 1024 files, named sequentially:\n",
        "      train-00000-of-01024\n",
        "      train-00001-of-01024\n",
        "      ...\n",
        "      train-01023-of-01024\n",
        "  The validation data is in the same format but sharded in 128 files.\n",
        "  The format of the data required is created by the script at:\n",
        "      https://github.com/tensorflow/tpu/blob/master/tools/datasets/imagenet_to_gcs.py\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               is_training,\n",
        "               use_bfloat16,\n",
        "               transpose_input,\n",
        "               data_dir,\n",
        "               image_size=224,\n",
        "               num_parallel_calls=8,\n",
        "               cache=False,\n",
        "               dataset_split=None,\n",
        "               shuffle_shards=False,\n",
        "               include_background_label=False,\n",
        "               augment_name=None,\n",
        "               randaug_num_layers=None,\n",
        "               randaug_magnitude=None):\n",
        "    \"\"\"Create an input from TFRecord files.\n",
        "    Args:\n",
        "      is_training: `bool` for whether the input is for training\n",
        "      use_bfloat16: If True, use bfloat16 precision; else use float32.\n",
        "      transpose_input: 'bool' for whether to use the double transpose trick\n",
        "      data_dir: `str` for the directory of the training and validation data; if\n",
        "        'null' (the literal string 'null') or implicitly False then construct a\n",
        "        null pipeline, consisting of empty images and blank labels.\n",
        "      image_size: `int` image height and width.\n",
        "      num_parallel_calls: concurrency level to use when reading data from disk.\n",
        "      cache: if true, fill the dataset by repeating from its cache\n",
        "      dataset_split: If provided, must be one of 'train' or 'validation' and\n",
        "        specifies the dataset split to read, overriding the default set by\n",
        "        is_training. In this case, is_training specifies whether the data is\n",
        "        augmented.\n",
        "      shuffle_shards: Whether to shuffle the dataset shards.\n",
        "      include_background_label: Whether to include the background label. If\n",
        "        this is True, then num_label_classes should be 1001. If False, then\n",
        "        num_label_classes should be 1000.\n",
        "      augment_name: `string` that is the name of the augmentation method\n",
        "        to apply to the image. `autoaugment` if AutoAugment is to be used or\n",
        "        `randaugment` if RandAugment is to be used. If the value is `None` no\n",
        "        no augmentation method will be applied applied. See autoaugment.py\n",
        "        for more details.\n",
        "      randaug_num_layers: 'int', if RandAug is used, what should the number of\n",
        "        layers be. See autoaugment.py for detailed description.\n",
        "      randaug_magnitude: 'int', if RandAug is used, what should the magnitude\n",
        "        be. See autoaugment.py for detailed description.\n",
        "    \"\"\"\n",
        "    super(ImageNetInput, self).__init__(\n",
        "        is_training=is_training,\n",
        "        image_size=image_size,\n",
        "        use_bfloat16=use_bfloat16,\n",
        "        transpose_input=transpose_input,\n",
        "        include_background_label=include_background_label,\n",
        "        augment_name=augment_name,\n",
        "        randaug_num_layers=randaug_num_layers,\n",
        "        randaug_magnitude=randaug_magnitude)\n",
        "    self.data_dir = data_dir\n",
        "    # TODO(b/112427086):  simplify the choice of input source\n",
        "    if self.data_dir == 'null' or not self.data_dir:\n",
        "      self.data_dir = None\n",
        "    self.num_parallel_calls = num_parallel_calls\n",
        "    self.cache = cache\n",
        "    self.dataset_split = dataset_split\n",
        "    self.shuffle_shards = shuffle_shards\n",
        "\n",
        "  def _get_null_input(self, data):\n",
        "    \"\"\"Returns a null image (all black pixels).\n",
        "    Args:\n",
        "      data: element of a dataset, ignored in this method, since it produces the\n",
        "        same null image regardless of the element.\n",
        "    Returns:\n",
        "      a tensor representing a null image.\n",
        "    \"\"\"\n",
        "    del data  # Unused since output is constant regardless of input\n",
        "    return tf.zeros([self.image_size, self.image_size, 3],\n",
        "                    tf.bfloat16 if self.use_bfloat16 else tf.float32)\n",
        "\n",
        "  def dataset_parser(self, value):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    if not self.data_dir:\n",
        "      return value, tf.constant(0, tf.int32)\n",
        "    return super(ImageNetInput, self).dataset_parser(value)\n",
        "\n",
        "  def make_source_dataset(self, index, num_hosts):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    if not self.data_dir:\n",
        "      tf.logging.info('Undefined data_dir implies null input')\n",
        "      return tf.data.Dataset.range(1).repeat().map(self._get_null_input)\n",
        "\n",
        "    # Shuffle the filenames to ensure better randomization.\n",
        "    if not self.dataset_split:\n",
        "      file_pattern = os.path.join(\n",
        "          self.data_dir, 'train-*' if self.is_training else 'validation-*')\n",
        "    else:\n",
        "      if self.dataset_split not in ['train', 'validation']:\n",
        "        raise ValueError(\n",
        "            \"If provided, dataset_split must be 'train' or 'validation', was %s\"\n",
        "            % self.dataset_split)\n",
        "      file_pattern = os.path.join(self.data_dir, self.dataset_split + '-*')\n",
        "\n",
        "    # For multi-host training, we want each hosts to always process the same\n",
        "    # subset of files.  Each host only sees a subset of the entire dataset,\n",
        "    # allowing us to cache larger datasets in memory.\n",
        "    dataset = tf.data.Dataset.list_files(\n",
        "        file_pattern, shuffle=self.shuffle_shards)\n",
        "    dataset = dataset.shard(num_hosts, index)\n",
        "\n",
        "    if self.is_training and not self.cache:\n",
        "      dataset = dataset.repeat()\n",
        "\n",
        "    def fetch_dataset(filename):\n",
        "      buffer_size = 8 * 1024 * 1024  # 8 MiB per file\n",
        "      dataset = tf.data.TFRecordDataset(filename, buffer_size=buffer_size)\n",
        "      return dataset\n",
        "\n",
        "    # Read the data from disk in parallel\n",
        "    dataset = dataset.apply(\n",
        "        tf.data.experimental.parallel_interleave(\n",
        "            fetch_dataset, cycle_length=64, sloppy=True))\n",
        "\n",
        "    if self.cache:\n",
        "      dataset = dataset.cache().apply(\n",
        "          tf.data.experimental.shuffle_and_repeat(1024 * 16))\n",
        "    else:\n",
        "      dataset = dataset.shuffle(1024)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Defines a selection of data from a Cloud Bigtable.\n",
        "BigtableSelection = collections.namedtuple('BigtableSelection', [\n",
        "    'project',\n",
        "    'instance',\n",
        "    'table',\n",
        "    'prefix',\n",
        "    'column_family',\n",
        "    'column_qualifier',\n",
        "])\n",
        "\n",
        "\n",
        "class ImageNetBigtableInput(ImageNetTFExampleInput):\n",
        "  \"\"\"Generates ImageNet input_fn from a Bigtable for training or evaluation.\"\"\"\n",
        "\n",
        "  def __init__(self, is_training, use_bfloat16, transpose_input, selection,\n",
        "               augment_name, randaug_num_layers, randaug_magnitude):\n",
        "    \"\"\"Constructs an ImageNet input from a BigtableSelection.\n",
        "    Args:\n",
        "      is_training: `bool` for whether the input is for training\n",
        "      use_bfloat16: If True, use bfloat16 precision; else use float32.\n",
        "      transpose_input: 'bool' for whether to use the double transpose trick\n",
        "      selection: a BigtableSelection specifying a part of a Bigtable.\n",
        "      augment_name: `string` that is the name of the augmentation method\n",
        "        to apply to the image. `autoaugment` if AutoAugment is to be used or\n",
        "        `randaugment` if RandAugment is to be used. If the value is `None` no\n",
        "        no augmentation method will be applied applied. See autoaugment.py\n",
        "        for more details.\n",
        "      randaug_num_layers: 'int', if RandAug is used, what should the number of\n",
        "        layers be. See autoaugment.py for detailed description.\n",
        "      randaug_magnitude: 'int', if RandAug is used, what should the magnitude\n",
        "        be. See autoaugment.py for detailed description.\n",
        "    \"\"\"\n",
        "    super(ImageNetBigtableInput, self).__init__(\n",
        "        is_training=is_training,\n",
        "        use_bfloat16=use_bfloat16,\n",
        "        transpose_input=transpose_input,\n",
        "        augment_name=augment_name,\n",
        "        randaug_num_layers=randaug_num_layers,\n",
        "        randaug_magnitude=randaug_magnitude)\n",
        "    self.selection = selection\n",
        "\n",
        "  def make_source_dataset(self, index, num_hosts):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    try:\n",
        "      from tensorflow.contrib.cloud import BigtableClient  # pylint: disable=g-import-not-at-top\n",
        "    except ImportError as e:\n",
        "      logging.exception('Bigtable is not supported in TensorFlow 2.x.')\n",
        "      raise e\n",
        "\n",
        "    data = self.selection\n",
        "    client = BigtableClient(data.project, data.instance)\n",
        "    table = client.table(data.table)\n",
        "    ds = table.parallel_scan_prefix(\n",
        "        data.prefix, columns=[(data.column_family, data.column_qualifier)])\n",
        "    # The Bigtable datasets will have the shape (row_key, data)\n",
        "    ds_data = ds.map(lambda index, data: data)\n",
        "\n",
        "    if self.is_training:\n",
        "      ds_data = ds_data.repeat()\n",
        "\n",
        "    return ds_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "wvIgYjlc5sPi"
      }
    }
  ]
}